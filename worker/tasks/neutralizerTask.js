const supabase = require('../supabaseClient');

const wait = (ms) => new Promise(resolve => setTimeout(resolve, ms));

function generateSlug(title) {
    return title.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/(^-|-$)+/g, '');
}

module.exports = {
    // 2 minutos
    delayMs: 2 * 60 * 1000,

    execute: async function ({ useOllama }) {
        console.log(`\n======================================`);
        console.log(`[丘뒲잺 Tarea: Neutralizer] Buscando notas pendientes de an치lisis...`);

        // Importamos din치micamente el servicio de IA seg칰n corresponda
        const aiService = useOllama ? require('../ollamaService') : require('../aiService');

        // Fetch up to 5 pending articles
        const { data: rawArticles, error: fetchError } = await supabase
            .from('raw_articles')
            .select('*')
            .eq('process_status', 'PENDING_ANALYSIS')
            .order('published_at', { ascending: true }) // Oldest first
            .limit(5);

        if (fetchError) {
            console.error("[X] Error fetching raw articles:", fetchError.message);
            return;
        }

        if (!rawArticles || rawArticles.length === 0) {
            console.log(`[!] No hay art칤culos crudos pendientes de procesar.`);
            return;
        }

        console.log(`[游닌] Encontrados ${rawArticles.length} art칤culos pendientes. Procesando...`);

        let processed = 0;

        for (const article of rawArticles) {
            console.log(`\n  -> Analizando: "${article.title.substring(0, 50)}..."`);

            try {
                const analysis = await aiService.analizarYExtraerCrudo(article.raw_text, article.title);

                if (!analysis || !analysis.objective_summary) {
                    console.warn(`  [丘멆잺] La IA no pudo devolver un an치lisis v치lido. Marcando como ERROR.`);
                    await supabase.from('raw_articles').update({ process_status: 'ERROR' }).eq('id', article.id);
                    continue;
                }

                // Create base slug, attach a random string to guarantee uniqueness
                const slug = generateSlug(article.title) + '-' + Math.random().toString(36).substring(2, 7);

                // Insert into neutral_news
                const { error: insertError } = await supabase
                    .from('neutral_news')
                    .insert([{
                        raw_article_id: article.id,
                        title: article.title,
                        slug: slug,
                        objective_summary: analysis.objective_summary,
                        original_bias_direction: analysis.original_bias_direction || 'Centro',
                        original_bias_score: analysis.original_bias_score || 0,
                        process_status: 'PENDING_GENERATION'
                    }]);

                if (insertError) {
                    console.error(`  [X] Error insertando neutral_news:`, insertError.message);
                    await supabase.from('raw_articles').update({ process_status: 'ERROR' }).eq('id', article.id);
                } else {
                    console.log(`  [+] Art칤culo neutralizado y clasificado (${analysis.original_bias_direction} ${analysis.original_bias_score}%).`);

                    // Mark raw_article as PROCESSED
                    await supabase.from('raw_articles').update({ process_status: 'PROCESSED' }).eq('id', article.id);
                    processed++;
                }
            } catch (err) {
                console.error(`  [X] Excepci칩n cr칤tica procesando art칤culo ${article.id}:`, err);
                await supabase.from('raw_articles').update({ process_status: 'ERROR' }).eq('id', article.id);
            }

            // Respect API rate limits
            await wait(2000);
        }

        console.log(`\n[九] Resumen Neutralizer: ${processed}/${rawArticles.length} art칤culos procesados exitosamente.`);
    }
};
